{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b6d9ef",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Facial Recognition- Create training data for my face1 model¶\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10897236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pywhatkit      #for whatsapp\n",
    "import boto3          #for aws cli\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import smtplib\n",
    "import imghdr\n",
    "from email.message import EmailMessage\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a6676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-2-eb1c9d3c2e61>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "### Step 1 - Create Training Data\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(image):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = image[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './user/face1/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb01fb6",
   "metadata": {},
   "source": [
    "# # Facial Recognition- Create training data for my face2 model¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527451a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-3-0c22dd1c5f8a>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(image):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = image[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './user/face2/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d44e0",
   "metadata": {},
   "source": [
    "\n",
    "# Training Face Model for face1 and face2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745edfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for face1 and face2 sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# Get the training data we previously madel\n",
    "training_data = []\n",
    "labels = []\n",
    "\n",
    "#1\n",
    "data_path = './user/face1/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    img_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    training_data.append(np.asarray(images, dtype=np.uint8))\n",
    "    labels.append(1)\n",
    "#2\n",
    "data_path = './user/face2/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    img_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    training_data.append(np.asarray(images, dtype=np.uint8))\n",
    "    labels.append(2)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "model.train(np.asarray(training_data), np.asarray(labels))\n",
    "\n",
    "model.write('model_save.yml')\n",
    "\n",
    "print(\"Model trained for face1 and face2 sucessefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932d107",
   "metadata": {},
   "source": [
    "\n",
    "# Run Facial Recognition Model and Send Email and whatsapp Msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3369e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mail(img):\n",
    "    Sender_Email = \"p.chinche111@gmail.com\"\n",
    "    Reciever_Email = \"nikchinche@gmail.com\"\n",
    "    Password=\"\"\n",
    "    h = open(\"pass.txt\", \"r\")\n",
    "    for line in h:\n",
    "        Password=line\n",
    "    h.close()\n",
    "    print(\"mail running\")\n",
    "    newMessage = EmailMessage()                         \n",
    "    newMessage['Subject'] = \"Face Successfullly detected\" \n",
    "    newMessage['From'] = Sender_Email                   \n",
    "    newMessage['To'] = Reciever_Email                   \n",
    "    newMessage.set_content('Image attached!')\n",
    "    \n",
    "    cv2.imwrite(\"face.jpg\",img)\n",
    "    with open('face.jpg', 'rb') as f:\n",
    "        image_data = f.read()\n",
    "        image_type = imghdr.what(f.name)\n",
    "        image_name = f.name\n",
    "        \n",
    "    newMessage.add_attachment(image_data, maintype='image', subtype=image_type, filename=image_name)\n",
    "    \n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
    "        smtp.login(Sender_Email, Password)              \n",
    "        smtp.send_message(newMessage)\n",
    "        print(\"logging in successfull\")\n",
    "        \n",
    "\n",
    "def whatsapp():\n",
    "    now = datetime.now()\n",
    "    H = int(now.strftime(\"%H\"))\n",
    "    M = int(now.strftime(\"%M\"))\n",
    "    pywhatkit.sendwhatmsg('+917721828724', 'HEY PRANAY!! FACE DETECTED ',H,M+1)\n",
    "    print(\"whatsApp success\")\n",
    "def aws():\n",
    "    subprocess.getoutput(\"terraform init\")\n",
    "    subprocess.getoutput('terraform apply --auto-approve')\n",
    "    print(\"AWS instance and 5 EBS Volumes Launched....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50ea8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 10 seconds web.whatsapp.com will open and after 20 seconds message will be delivered\n",
      "whatsApp success\n",
      "mail running\n",
      "logging in successfull\n"
     ]
    }
   ],
   "source": [
    "flag1=0\n",
    "flag2=0\n",
    "warnings. filterwarnings(action='ignore')\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\n",
    "model.read('model_save.yml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident'\n",
    "            \n",
    "        \n",
    "        \n",
    "        if results[0]==1:\n",
    "            if (confidence > 80) and flag1==0:\n",
    "                \n",
    "                cv2.putText(image, \"Hello, Pranay\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.putText(image, display_string, (0, 50), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,255,250), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                if(cv2.waitKey(2)==13):\n",
    "                    whatsapp()\n",
    "                    mail(face)\n",
    "                    flag1=1\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "        elif(results[0]==2):\n",
    "            if (confidence > 80)and flag2==0:\n",
    "                cv2.putText(image, \"Hello, Pranay2\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.putText(image, display_string, (0, 50), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,255,250), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                if(cv2.waitKey(2)==13):\n",
    "                    aws()\n",
    "                    flag2=1\n",
    "                            \n",
    "         \n",
    "        else: \n",
    "            cv2.putText(image, \"Unknown Person\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"NO FACE FOUND\", (220, 120) , cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Looking for Face\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        \n",
    "        \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f53e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
